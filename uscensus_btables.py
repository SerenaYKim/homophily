# -*- coding: utf-8 -*-
"""USCensus-BTables.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1V_mYief1w7LFAMlo6VFDPH2MC1sWULrA
"""

import pandas as pd
import requests

def fetch_census_data(year, geography, states, columns, api_key):
    """
    Fetches census data for a given year and geography for all states.
    """
    HOST = 'https://api.census.gov/data/'
    data_path = "/acs/acs5?get="
    df = pd.DataFrame()
    for state in states:
        url = f"{HOST}{year}{data_path}{','.join(columns)}&for={geography}:*&in=state:{state}&key={api_key}"
        response = requests.get(url)
        data = response.json()
        temp_df = pd.DataFrame(data[1:], columns=data[0])
        temp_df["year"] = year
        df = pd.concat([df, temp_df], ignore_index=True)
    return df

def preprocess_data(df, column_mapping):
    """
    Renames columns, converts types, and calculates additional metrics.
    """
    # Rename columns
    df.rename(columns=column_mapping, inplace=True)

    # Convert data types
    df = df.convert_dtypes()
    for column in set(column_mapping.values()) - {"GEO_ID"}:
        df[column] = pd.to_numeric(df[column], errors='coerce')

    # Calculate additional metrics dynamically
    for key in column_mapping.values():
        if key in df.columns and key not in ["GEO_ID", "Population"]:
            df[f"Pr_{key}"] = df[key] / df["Population"]

    # Keep only necessary columns
    keep_columns = ["GEO_ID", "year", "Population", "Hispanic"] + [f"Pr_{key}" for key in column_mapping.values() if key not in ["GEO_ID", "Population"]]
    return df[keep_columns]

def save_to_csv(df, filepath):
    df.to_csv(filepath, index=False)

if __name__ == "__main__":
    # Configuration
    geography = "tract"
    years = ["2020"]#, "2021", "2022"
    api_key = "YourAPIKey"
    states = [
        "01", "02", "04", "05", "06", "08", "09", "10", "11", "12",
        "13", "15", "16", "17", "18", "19", "20", "21", "22", "23",
        "24", "25", "26", "27", "28", "29", "30", "31", "32", "33",
        "34", "35", "36", "37", "38", "39", "40", "41", "42", "44",
        "45", "46", "47", "48", "49", "50", "51", "53", "54", "55", "56"]

    # Add more columns as needed
    column_mapping = {
        "GEO_ID": "GEO_ID",
        'B03002_001E': "Population",
        'B03002_003E': "White",
        'B03002_004E': "Black",
        "B03002_005E": "Native",
        "B03002_006E": "Asian",
        "B03002_007E": "Hawaiian",
        "B03002_008E": "Otherrace",
        "B03002_009E": "Multirace",
        "B03002_012E": "Hispanic",
    }

    # Fetch and process data
    df_multiyear = pd.DataFrame()
    for year in years:
        colinput = list(column_mapping.keys())
        df_year = fetch_census_data(year, geography, states, colinput, api_key)
        df_processed = preprocess_data(df_year, column_mapping)
        df_multiyear = pd.concat([df_multiyear, df_processed])

    # Save results
    save_to_csv(df_multiyear, f"/content/drive/MyDrive/H08-ResilienceIndex/data/homophily/raw/race-B03002-{year}-{geography}.csv")

