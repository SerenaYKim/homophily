# -*- coding: utf-8 -*-
"""USCensus-STables.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19DwODFTIejZN1FRBl0Mgm0wFpbU5Q125
"""

import pandas as pd
import requests

def fetch_census_data_tableS(api_key, geography, colnamedict, years, var, states):
    """
    Fetches ACS Subject Tables data for a given list of years and states, for a specified geography and variable group.
    """
    HOST = 'https://api.census.gov/data/'
    data_path = f"/acs/acs5/subject?get=group({var})"

    df = pd.DataFrame()

    for year in years:
        for state in states:
            url = f"{HOST}{year}{data_path}&for={geography}:*&in=state:{state}&key={api_key}"
            resp = requests.get(url)
            if resp.status_code == 200:  # Check if the request was successful
                unit = resp.json()
                df_temp = pd.DataFrame(unit[1:], columns=unit[0])
                df_temp["year"] = year
                df = pd.concat([df, df_temp], ignore_index=True)

    return df

def preprocess_and_save(df, colnamedict, directory, var, year, geography):
    """
    Renames columns, calculates fips, and saves the processed DataFrame to a CSV file.
    """
    df.rename(columns=colnamedict, inplace=True)
    df["fips"] = df["GEO_ID"].str[9:].astype(int)

    coloutput = list(colnamedict.values())

    # Convert percentages to proportions
    df = df.convert_dtypes()
    for column in set(colnamedict.values()) - {"GEO_ID"}:
        df[column] = pd.to_numeric(df[column], errors='coerce')
        df[column] = df[column].astype(float) * 0.01

    default = ["state", "county", "NAME", "year", "fips"]
    varnames = coloutput + default
    df = df[varnames]

    df.sort_values(by=["year"], ascending=False, ignore_index=True, inplace=True)
    filepath = f"{directory}lang-{var}-{year}-{geography}.csv"
    df.to_csv(filepath, index=False)

# Main code
if __name__ == "__main__":
    api_key =  "# Your API Key Here" # Your API Key Here
    geography = "county"  # Available options: "county", "tract", "block group", "place"
    years = ["2020"]  # "2010", "2011", "2012", "2013", "2014", "2015", "2016", "2017", "2018", "2019", "2020", "2021" for most variables
    directory = "/content/drive/MyDrive/H08-ResilienceIndex/data/homophily/raw/" # "/path_to_your_directory/"
    states = [
        "01", "02", "04", "05", "06", "08", "09", "10", "11", "12",
        "13", "15", "16", "17", "18", "19", "20", "21", "22", "23",
        "24", "25", "26", "27", "28", "29", "30", "31", "32", "33",
        "34", "35", "36", "37", "38", "39", "40", "41", "42", "44",
        "45", "46", "47", "48", "49", "50", "51", "53", "54", "55", "56"]

    # Add more columns as needed
    varS1601 = "S1601"
    colnamedict_S1601 = {
        "GEO_ID": "GEO_ID",
        "S1601_C02_002E": "Pr_EnglishAtHome",
        "S1601_C02_004E": "Pr_SpanishAtHome",
        "S1601_C02_008E": "Pr_IndoEuropeanAtHome",
        "S1601_C02_012E": "Pr_AsianLanguageAtHome",
        "S1601_C06_001E": "Pr_EngLessThanWell"
    }

    df = fetch_census_data_tableS(api_key, geography, colnamedict_S1601, years, varS1601, states)
    preprocess_and_save(df, colnamedict_S1601, directory, varS1601, years[0], geography)

df = pd.read_csv("/content/drive/MyDrive/H08-ResilienceIndex/data/homophily/raw/lang-S1601-2020-county.csv")
df

